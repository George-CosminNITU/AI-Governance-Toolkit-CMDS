# Corporate AI Acceptable Use Policy (AUP) - Initial Skeleton
**Version:** 0.1 (Draft)
**Date:** February 8, 2026
**Status:** Semester 1 Deliverable

## 1. Purpose and Scope
The purpose of this policy is to define the acceptable use of Generative AI tools within the organization to protect intellectual property and ensure compliance with the EU AI Act.
* **Scope:** Applies to all employees, contractors, and third-party vendors.
* **Covered Tools:** ChatGPT, Microsoft Copilot, Gemini, Midjourney, and any other LLM-based application.

## 2. Roles and Responsibilities
* **IT Security:** Responsible for vetting and whitelisting AI tools.
* **Legal/Compliance:** Responsible for updating policy based on regulatory changes (EU AI Act).
* **Department Heads:** Responsible for approving specific use-cases for their teams.
* **End Users:** Responsible for verifying all AI-generated output (Human-in-the-Loop).

## 3. Data Classification & Usage Guidelines
| Data Classification | Definition | Permitted AI Usage |
| :--- | :--- | :--- |
| **Public** | Information intended for public release (marketing copy, press releases). | ✅ Allowed on all approved tools. |
| **Internal** | Non-sensitive business operations (internal memos, meeting agendas). | ⚠️ Allowed ONLY on Enterprise versions with Data Protection. |
| **Confidential** | PII, Source Code, Financial Data, Strategic Plans. | ❌ STRICTLY PROHIBITED on external AI models. |

## 4. Prohibited Use Cases
1.  Uploading customer PII (GDPR violation).
2.  Pasting proprietary source code into public models (IP leakage).
3.  Generating content that violates copyright laws.
4.  Using AI to make automated decisions about employees (Hiring/Firing) without human review.

## 5. Human-in-the-Loop (HITL) Protocol
All content generated by AI must be reviewed by a human before publication or action. Users must flag and correct:
* Hallucinations (factual errors).
* Bias or discriminatory language.
* Copyrighted material.
